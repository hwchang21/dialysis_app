final_lm_formula <- as.formula(paste("Outcomes ~", paste(non_zero_vars, collapse = " + ")))
linear_model <- lm(final_lm_formula, data = dta_scaled)
vif_values <- vif(linear_model)
print(vif_values)
if (!inherits(multi_cox, "try-error") && !any(is.na(coef(multi_cox)))) {
summary_multi_cox <- summary(multi_cox)
coefficients <- summary_multi_cox$coefficient
conf_int <- summary_multi_cox$conf.int
# 获取显著变量
significant_vars <- rownames(coefficients)[coefficients[, "Pr(>|z|)"] < 0.05]
# 创建数据框保存结果
multi_cox_results <- data.frame(
Variable = rownames(coefficients),
HR = format(round(exp(coefficients[, "coef"]), 2), nsmall = 2),
`P` = format(round(coefficients[, "Pr(>|z|)"], 2), nsmall = 2),
CI5 = format(round(conf_int[, "lower .95"], 2), nsmall = 2),
CI95 = format(round(conf_int[, "upper .95"], 2), nsmall = 2)
)
# 以CI5 - CI95形式表示置信区间
multi_cox_results$CI <- paste(multi_cox_results$CI5, "-", multi_cox_results$CI95)
# 查看结果
View(multi_cox_results)
# 对每个显著变量进行单因素 Cox 回归分析
# 批量单因素回归模型建立:Uni_cox_model
Uni_cox_model<-function(x){
FML<- as.formula(paste0 ("y~",x))
cox<-coxph(FML,data=dta_scaled)
cox1<-summary(cox)
HR<-round(cox1$coefficients[,2],2)
PValue<- round(cox1$coefficients[,5],3)
CI5<- round(cox1$conf.int[,3],2)
CI95<- round(cox1$conf.int[,4],2)
Uni_cox_model<- data.frame('Characteristics' = x,
'HR' = HR,
'CI5' = CI5,
'CI95' = CI95,
'P'= PValue)
return(Uni_cox_model)}
# 输出结果
Uni_cox <- lapply(significant_vars,Uni_cox_model)
# 合并所有单因素 Cox 回归结果
Uni_cox <- bind_rows(Uni_cox)
#优化表格，这里举例HR+95% CI+P 风格
Uni_cox$CI<-paste(Uni_cox$CI5,'-',Uni_cox$CI95)
Uni_cox<-Uni_cox[,-3:-4]
#查看单因素cox表格
View(Uni_cox)
if (length(significant_vars) > 0) {
final_svm_formula <- as.formula(paste("Outcomes ~", paste(significant_vars, collapse = " + ")))
# 设置训练控制
set.seed(123)
train_control <- trainControl(method = "cv", number = 10,
classProbs = TRUE, summaryFunction = twoClassSummary)
# 检查 Outcomes 列的唯一值
unique_outcomes <- unique(dta_scaled$Outcomes)
print(unique_outcomes)
# 确保 Outcomes 是因子变量，并且因子水平是有效的 R 变量名称
dta_scaled$Outcomes <- factor(dta_scaled$Outcomes, levels = c(0, 1), labels = c("Class0", "Class1"))
# 训练SVM模型
svm_model <- train(final_svm_formula,
data = dta_scaled,
method = "svmRadial",
trControl = train_control,
metric = "ROC",
preProcess = c("center", "scale"))
# 将对象保存为.RData文件
save(svm_model, file = "//Users//huaiwenchang//Desktop//FDU D.Sc.//Aging/2023.5.18 Incremental Dialysis//Analysis//模型封装//shiny_app//svm_model.RData")
# 预测概率
risk_scores <- predict(svm_model, dta_scaled, type = "prob")
print(colnames(risk_scores))  # 查看概率输出的列名
# 确认阳性类的列名，并使用相应的列名
positive_class <- "Class1"  # 或根据列名修改为实际的阳性类名称
if (!(positive_class %in% colnames(risk_scores))) {
stop("阳性类列名不在预测概率输出中。")
}
probabilities <- risk_scores[, positive_class]
print("Probabilities:")
print(head(probabilities))
print(summary(probabilities))  # 打印概率的统计信息
if (is.null(probabilities) || length(probabilities) == 0) {
stop("SVM model did not return probabilities.")
}
# 处理probabilities中的NA值
if (any(is.na(probabilities))) {
probabilities[is.na(probabilities)] <- median(probabilities, na.rm = TRUE)
}
# 使用ifelse逻辑计算预测结果
median_risk <- median(probabilities)
dta_scaled$predicted_outcome <- ifelse(probabilities > median_risk, 1, 0)
dta_scaled$predicted_outcome <- factor(dta_scaled$predicted_outcome,
levels = c(0, 1), labels = c("Class0", "Class1"))
# 计算评估指标
confusion <- confusionMatrix(as.factor(dta_scaled$predicted_outcome), as.factor(dta_scaled$Outcomes))
# 计算 ROC 曲线并设置水平和方向，隐藏提示信息
roc_curve <- suppressMessages(roc(as.factor(dta_scaled$Outcomes), probabilities, levels = c("Class0", "Class1"), direction = "<"))
# 计算 AUC
auc_value <- auc(roc_curve)
# 添加 AUC 到评估指标中
# 将评估指标和 AUC 保留两位小数
evaluation_metrics <- c(
accuracy = round(confusion$overall['Accuracy'], 2),
sensitivity = round(confusion$byClass['Sensitivity'], 2),
specificity = round(confusion$byClass['Specificity'], 2),
precision = round(confusion$byClass['Precision'], 2),
recall = round(confusion$byClass['Recall'], 2),
f1_score = round(confusion$byClass['F1'], 2),
auc = round(auc_value, 2)
)
# 打印评估指标，包括 AUC
print("Evaluation Metrics:")
print(evaluation_metrics)
# 定义boot函数
boot_fn <- function(data, indices) {
d <- data[indices, ]
svm_model <- train(final_svm_formula, data = d, method = "svmRadial",
trControl = train_control, metric = "ROC")
risk_scores <- predict(svm_model, d, type = "prob")
positive_class <- "Class1"  # 根据实际情况设置阳性类的名称
probabilities <- risk_scores[, positive_class]
if (is.null(probabilities) || length(probabilities) == 0) {
return(rep(NA, 7))  # 返回NA，防止bootstrap失败
}
median_risk <- median(probabilities)
d$predicted_outcome <- ifelse(probabilities > median_risk, 1, 0)
d$predicted_outcome <- factor(d$predicted_outcome, levels = c(0, 1),
labels = c("Class0", "Class1"))
# 计算混淆矩阵
confusion <- confusionMatrix(as.factor(d$predicted_outcome), as.factor(d$Outcomes))
# 计算 ROC 曲线
roc_curve <- suppressMessages(roc(as.factor(d$Outcomes), probabilities))
auc_value <- auc(roc_curve)
# 返回包括AUC在内的评估指标
c(
accuracy = confusion$overall['Accuracy'],
sensitivity = confusion$byClass['Sensitivity'],
specificity = confusion$byClass['Specificity'],
precision = confusion$byClass['Precision'],
recall = confusion$byClass['Recall'],
f1_score = confusion$byClass['F1'],
auc = auc_value
)
}
# 设置随机种子以保证bootstrap结果可重复
set.seed(123)
# 进行bootstrap
boot_results <- boot(data = dta_scaled, statistic = boot_fn, R = 100, parallel = "no")
# 计算每个指标的95%置信区间
ci_accuracy <- round(boot.ci(boot_results, index = 1, type = "perc")$percent[4:5],2)
ci_sensitivity <- round(boot.ci(boot_results, index = 2, type = "perc")$percent[4:5],2)
ci_specificity <- round(boot.ci(boot_results, index = 3, type = "perc")$percent[4:5],2)
ci_precision <- round(boot.ci(boot_results, index = 4, type = "perc")$percent[4:5],2)
ci_recall <- round(boot.ci(boot_results, index = 5, type = "perc")$percent[4:5],2)
ci_f1_score <- round(boot.ci(boot_results, index = 6, type = "perc")$percent[4:5],2)
ci_auc <- round(boot.ci(boot_results, index = 7, type = "perc")$percent[4:5],2)
# 计算每个指标的均值
evaluation_metrics <- colMeans(boot_results$t, na.rm = TRUE)
# 创建数据框存储结果
results <- data.frame(
Metric = c("Accuracy", "Sensitivity", "Specificity", "Precision", "Recall", "F1-score", "AUC"),
Value = round(c(evaluation_metrics[1],
evaluation_metrics[2],
evaluation_metrics[3],
evaluation_metrics[4],
evaluation_metrics[5],
evaluation_metrics[6],
evaluation_metrics[7]),2),
CI = paste0("[",
round(c(ci_accuracy[1], ci_sensitivity[1], ci_specificity[1], ci_precision[1], ci_recall[1], ci_f1_score[1], ci_auc[1]), 2),
" - ",
round(c(ci_accuracy[2], ci_sensitivity[2], ci_specificity[2], ci_precision[2], ci_recall[2], ci_f1_score[2], ci_auc[2]), 2),
"]")
)
# 查看结果
View(results)
} else {
cat("没有显著的变量用于构建评分预测表。\n")
}
} else {
cat("标准Cox模型不收敛或系数为NA，请调整lambda值或检查数据。\n")
}
} else {
cat("没有选中的变量，请调整lambda值或检查数据。\n")
}
shiny::runApp('Desktop/FDU D.Sc./Aging/2023.5.18 Incremental Dialysis/Analysis/模型封装/shiny_app')
runApp('Desktop/FDU D.Sc./Aging/2023.5.18 Incremental Dialysis/Analysis/模型封装/shiny_app')
runApp('Desktop/FDU D.Sc./Aging/2023.5.18 Incremental Dialysis/Analysis/模型封装/shiny_app')
runApp('Desktop/FDU D.Sc./Aging/2023.5.18 Incremental Dialysis/Analysis/模型封装/shiny_app')
# 选择患者
# 48以前都是class1 以后都是class0
patient <- c(20, 70)
# 创建一个空的列表来存储每个患者的 SHAP 图
shap_plots <- list()
# 循环计算每个患者的 SHAP 值并绘制 SHAP 图
for (i in seq_along(c(1,2))) {
num <- patient[i]
# 计算 SHAP 值
shapley <- Shapley$new(predictor, x.interest = X[num, ])
# 获取 SHAP 值
shap_values <- shapley$results
# 替换 SHAP 值中的标准化数据为原始数据
original_values <- dta_original[complete_cases, significant_vars]
# 列名映射
colnames_mapping <- c("ProBNP" = "ProBNP",
"尿量" = "Urine output",
"stdktv" = "std Kt/v",
"npcr" = "npcr",
"透后收缩压" = "Post dialysis SBP",
"白细胞计数" = "WBC count",
"血红蛋白" = "Hemoglobin",
"g_kg_d" = "Daily Protein Per Kilogram")
# 获取原始列名
current_colnames <- colnames(original_values)
# 替换列名
new_colnames <- colnames_mapping[current_colnames]
# 更新列名
colnames(original_values) <- new_colnames
# 提取第num行的原始数据
first_row_data <- original_values[num, ]
# 获取指标名
feature_names <- names(first_row_data)
# 将指标名和对应的数据整合成新的命名格式
new_names <- paste0(feature_names, ":", round(first_row_data, 2))
# 替换 SHAP 值中的标准化数据为原始数据，命名为 "指标名 = 数据"
shapley$results$x.interest <- as.list(new_names)
# 替换 SHAP 值中的标准化数据为原始数据，命名为 "指标名:数据"
shapley$results$feature.value <- new_names
# 替换 SHAP 值中的标准化数据为原始数据，命名为 "指标名:数据"
shapley$results$feature.value <- sapply(shapley$results$x.interest, function(x) x[1])
# 提取显著变量对应的 SHAP 值，只选择 Class0
shap_values_class0 <- shapley$results %>%
filter(feature %in% significant_vars, class == "Class0") %>%
select(feature, phi, feature.value, x.interest)
# 提取 SHAP 值和特征名
shap_phi_class0 <- shap_values_class0$phi
shap_features_class0 <- shap_values_class0$feature
# 使用 dplyr 确保所有列长度相同
shap_values_class0 <- tibble(
Feature = shap_features_class0,
SHAP_Value = shap_phi_class0,  # 提取显著变量对应的 SHAP 值
Original_Value = new_names
)
# 获取患者的特征数据
patient_features <- dta_scaled[num, significant_vars, drop = FALSE]
# 使用模型进行预测，获取每个类的概率
predicted_probabilities <- predict(svm_model,
newdata = patient_features,
type = "prob")
# 获取判断为 Class0 和 Class1 的概率
class0_probability <- predicted_probabilities[1, "Class0"] * 100
class1_probability <- predicted_probabilities[1, "Class1"] * 100
# 打印各类的概率
print(predicted_probabilities)
# 绘制 SHAP Summary Plot for Class0
shap_plots[[i*2-1]] <- ggplot(shap_values_class0, aes(x = reorder(Original_Value, SHAP_Value), y = SHAP_Value, fill = SHAP_Value > 0)) +
geom_bar(stat = "identity") +
geom_text(aes(label = sprintf("%.2f", SHAP_Value)),
vjust = 0.5, color = "black", size = 3) +  # 在柱子上添加 SHAP 值文本标签，并将文本标签放置在中间
coord_flip() +
scale_fill_manual(values = c("#87CEEB", "#FFA500")) +  # 手动设置颜色映射
labs(title = paste("Patient ID:", num, "- Low risk - Probability:",
sprintf("%.2f%%", class0_probability ))) +
theme_minimal() +
theme(axis.title.x = element_blank(),  # 移除 x 轴标签
axis.title.y = element_blank(),  # 移除 y 轴标签
legend.position = "none",  # 移除图例
axis.text.x = element_text(color = "black", face = "bold"),  # 设置 x 轴刻度标签颜色和加粗
axis.text.y = element_text(color = "black", face = "bold"),  # 设置 y 轴刻度标签颜色和加粗
text = element_text(family = "STHeiti"),
plot.margin = unit(rep(1, 4), "cm"))  # 调整图形的边距
# 提取显著变量对应的 SHAP 值，只选择 Class1
shap_values_class1 <- shapley$results %>%
filter(feature %in% significant_vars, class == "Class1") %>%
select(feature, phi, feature.value, x.interest)
# 提取 SHAP 值和特征名
shap_phi_class1 <- shap_values_class1$phi
shap_features_class1 <- shap_values_class1$feature
# 使用 dplyr 确保所有列长度相同
shap_values_class1 <- tibble(
Feature = shap_features_class1,
SHAP_Value = shap_phi_class1,  # 提取显著变量对应的 SHAP 值
Original_Value = new_names
)
# 绘制 SHAP Summary Plot for Class1
shap_plots[[i*2]] <- ggplot(shap_values_class1, aes(x = reorder(Original_Value, SHAP_Value), y = SHAP_Value, fill = SHAP_Value > 0)) +
geom_bar(stat = "identity") +
geom_text(aes(label = sprintf("%.2f", SHAP_Value)),
vjust = 0.5, color = "black", size = 3) +  # 在柱子上添加 SHAP 值文本标签，并将文本标签放置在中间
coord_flip() +
scale_fill_manual(values = c("#87CEEB", "#FFA500")) +  # 手动设置颜色映射
labs(title = paste("Patient ID:", num, "- High risk - Probability:",
sprintf("%.2f%%", class1_probability ))) +
theme_minimal() +
theme(axis.title.x = element_blank(),  # 移除 x 轴标签
axis.title.y = element_blank(),  # 移除 y 轴标签
legend.position = "none",  # 移除图例
axis.text.x = element_text(color = "black", face = "bold"),  # 设置 x 轴刻度标签颜色和加粗
axis.text.y = element_text(color = "black", face = "bold"),  # 设置 y 轴刻度标签颜色和加粗
text = element_text(family = "STHeiti"),
plot.margin = unit(rep(1, 4), "cm"))  # 调整图形的边距
}
# 计算SHAP值(个体)
# 准备解释对象
X <- dta_scaled %>% select(all_of(significant_vars))
y <- dta_scaled$Outcomes
# 删除包含缺失值的行
complete_cases <- complete.cases(X, y)
X <- X[complete_cases, ]
y <- y[complete_cases]
# 将因子变量转换为数字
y_numeric <- as.numeric(y) - 1
# 再次检查 y 是否包含 NA 值
if (any(is.na(y_numeric))) {
stop("标签y中仍然包含NA值，请检查数据。")
}
# 创建Predictor对象
predictor <- Predictor$new(
model = svm_model,
data = X,
y = y_numeric,
type = "prob" # 确保使用概率输出
)
# 选择患者
# 48以前都是class1 以后都是class0
patient <- c(20, 70)
# 创建一个空的列表来存储每个患者的 SHAP 图
shap_plots <- list()
# 循环计算每个患者的 SHAP 值并绘制 SHAP 图
for (i in seq_along(c(1,2))) {
num <- patient[i]
# 计算 SHAP 值
shapley <- Shapley$new(predictor, x.interest = X[num, ])
# 获取 SHAP 值
shap_values <- shapley$results
# 替换 SHAP 值中的标准化数据为原始数据
original_values <- dta_original[complete_cases, significant_vars]
# 列名映射
colnames_mapping <- c("ProBNP" = "ProBNP",
"尿量" = "Urine output",
"stdktv" = "std Kt/v",
"npcr" = "npcr",
"透后收缩压" = "Post dialysis SBP",
"白细胞计数" = "WBC count",
"血红蛋白" = "Hemoglobin",
"g_kg_d" = "Daily Protein Per Kilogram")
# 获取原始列名
current_colnames <- colnames(original_values)
# 替换列名
new_colnames <- colnames_mapping[current_colnames]
# 更新列名
colnames(original_values) <- new_colnames
# 提取第num行的原始数据
first_row_data <- original_values[num, ]
# 获取指标名
feature_names <- names(first_row_data)
# 将指标名和对应的数据整合成新的命名格式
new_names <- paste0(feature_names, ":", round(first_row_data, 2))
# 替换 SHAP 值中的标准化数据为原始数据，命名为 "指标名 = 数据"
shapley$results$x.interest <- as.list(new_names)
# 替换 SHAP 值中的标准化数据为原始数据，命名为 "指标名:数据"
shapley$results$feature.value <- new_names
# 替换 SHAP 值中的标准化数据为原始数据，命名为 "指标名:数据"
shapley$results$feature.value <- sapply(shapley$results$x.interest, function(x) x[1])
# 提取显著变量对应的 SHAP 值，只选择 Class0
shap_values_class0 <- shapley$results %>%
filter(feature %in% significant_vars, class == "Class0") %>%
select(feature, phi, feature.value, x.interest)
# 提取 SHAP 值和特征名
shap_phi_class0 <- shap_values_class0$phi
shap_features_class0 <- shap_values_class0$feature
# 使用 dplyr 确保所有列长度相同
shap_values_class0 <- tibble(
Feature = shap_features_class0,
SHAP_Value = shap_phi_class0,  # 提取显著变量对应的 SHAP 值
Original_Value = new_names
)
# 获取患者的特征数据
patient_features <- dta_scaled[num, significant_vars, drop = FALSE]
# 使用模型进行预测，获取每个类的概率
predicted_probabilities <- predict(svm_model,
newdata = patient_features,
type = "prob")
# 获取判断为 Class0 和 Class1 的概率
class0_probability <- predicted_probabilities[1, "Class0"] * 100
class1_probability <- predicted_probabilities[1, "Class1"] * 100
# 打印各类的概率
print(predicted_probabilities)
# 绘制 SHAP Summary Plot for Class0
shap_plots[[i*2-1]] <- ggplot(shap_values_class0, aes(x = reorder(Original_Value, SHAP_Value), y = SHAP_Value, fill = SHAP_Value > 0)) +
geom_bar(stat = "identity") +
geom_text(aes(label = sprintf("%.2f", SHAP_Value)),
vjust = 0.5, color = "black", size = 3) +  # 在柱子上添加 SHAP 值文本标签，并将文本标签放置在中间
coord_flip() +
scale_fill_manual(values = c("#87CEEB", "#FFA500")) +  # 手动设置颜色映射
labs(title = paste("Patient ID:", num, "- Low risk - Probability:",
sprintf("%.2f%%", class0_probability ))) +
theme_minimal() +
theme(axis.title.x = element_blank(),  # 移除 x 轴标签
axis.title.y = element_blank(),  # 移除 y 轴标签
legend.position = "none",  # 移除图例
axis.text.x = element_text(color = "black", face = "bold"),  # 设置 x 轴刻度标签颜色和加粗
axis.text.y = element_text(color = "black", face = "bold"),  # 设置 y 轴刻度标签颜色和加粗
text = element_text(family = "STHeiti"),
plot.margin = unit(rep(1, 4), "cm"))  # 调整图形的边距
# 提取显著变量对应的 SHAP 值，只选择 Class1
shap_values_class1 <- shapley$results %>%
filter(feature %in% significant_vars, class == "Class1") %>%
select(feature, phi, feature.value, x.interest)
# 提取 SHAP 值和特征名
shap_phi_class1 <- shap_values_class1$phi
shap_features_class1 <- shap_values_class1$feature
# 使用 dplyr 确保所有列长度相同
shap_values_class1 <- tibble(
Feature = shap_features_class1,
SHAP_Value = shap_phi_class1,  # 提取显著变量对应的 SHAP 值
Original_Value = new_names
)
# 绘制 SHAP Summary Plot for Class1
shap_plots[[i*2]] <- ggplot(shap_values_class1, aes(x = reorder(Original_Value, SHAP_Value), y = SHAP_Value, fill = SHAP_Value > 0)) +
geom_bar(stat = "identity") +
geom_text(aes(label = sprintf("%.2f", SHAP_Value)),
vjust = 0.5, color = "black", size = 3) +  # 在柱子上添加 SHAP 值文本标签，并将文本标签放置在中间
coord_flip() +
scale_fill_manual(values = c("#87CEEB", "#FFA500")) +  # 手动设置颜色映射
labs(title = paste("Patient ID:", num, "- High risk - Probability:",
sprintf("%.2f%%", class1_probability ))) +
theme_minimal() +
theme(axis.title.x = element_blank(),  # 移除 x 轴标签
axis.title.y = element_blank(),  # 移除 y 轴标签
legend.position = "none",  # 移除图例
axis.text.x = element_text(color = "black", face = "bold"),  # 设置 x 轴刻度标签颜色和加粗
axis.text.y = element_text(color = "black", face = "bold"),  # 设置 y 轴刻度标签颜色和加粗
text = element_text(family = "STHeiti"),
plot.margin = unit(rep(1, 4), "cm"))  # 调整图形的边距
}
patient_features
runApp('Desktop/FDU D.Sc./Aging/2023.5.18 Incremental Dialysis/Analysis/模型封装/shiny_app')
# 获取判断为 Class0 和 Class1 的概率
class0_probability <- predicted_probabilities[1, "Class0"] * 100
class1_probability <- predicted_probabilities[1, "Class1"] * 100
# 打印各类的概率
print(predicted_probabilities)
median_risk <- median(probabilities)
median_risk
runApp('Desktop/FDU D.Sc./Aging/2023.5.18 Incremental Dialysis/Analysis/模型封装/shiny_app')
runApp('Desktop/FDU D.Sc./Aging/2023.5.18 Incremental Dialysis/Analysis/模型封装/shiny_app')
original_values
runApp('Desktop/FDU D.Sc./Aging/2023.5.18 Incremental Dialysis/Analysis/模型封装/shiny_app')
# 检查和运行
# 本地测试：在部署之前，本地运行app.R以确保没有错误：
library(shiny)
# 切换到包含 app.R 和 significant_cox.RData 文件的目录
setwd("//Users//huaiwenchang//Desktop//FDU D.Sc.//Aging/2023.5.18 Incremental Dialysis//Analysis//模型封装//shiny_app")
# 运行应用程序
shiny::runApp(".")
# 在 R 中查看日志
rsconnect::showLogs(appName = "shiny_app", entries = 100)
# 确认数据文件路径
# 在控制台中运行
load("//Users//huaiwenchang//Desktop//FDU D.Sc.//Aging/2023.5.18 Incremental Dialysis//Analysis//模型封装//shiny_app//significant_cox.RData")
# 确认数据文件路径
# 在控制台中运行
load("//Users//huaiwenchang//Desktop//FDU D.Sc.//Aging/2023.5.18 Incremental Dialysis//Analysis//模型封装//shiny_app//svm_model.RData")
# 确认依赖包是否正确安装
required_packages <- c("shiny", "e1071")
installed_packages <- installed.packages()
for (pkg in required_packages) {
if (!pkg %in% installed_packages) {
install.packages(pkg)
}
}
# 确认上述步骤都没有问题后，重新部署应用程序
rsconnect::deployApp(appDir = "//Users//huaiwenchang//Desktop//FDU D.Sc.//Aging/2023.5.18 Incremental Dialysis//Analysis//模型封装//shiny_app", forceUpdate = TRUE)
runApp()
runApp()
# 运行应用程序
shiny::runApp(".")
# 在 R 中查看日志
rsconnect::showLogs(appName = "shiny_app", entries = 100)
# 确认上述步骤都没有问题后，重新部署应用程序
rsconnect::deployApp(appDir = "//Users//huaiwenchang//Desktop//FDU D.Sc.//Aging/2023.5.18 Incremental Dialysis//Analysis//模型封装//shiny_app", forceUpdate = TRUE)
# 在 R 中查看日志
rsconnect::showLogs(appName = "shiny_app", entries = 100)
runApp()
# 确认上述步骤都没有问题后，重新部署应用程序
rsconnect::deployApp(appDir = "//Users//huaiwenchang//Desktop//FDU D.Sc.//Aging/2023.5.18 Incremental Dialysis//Analysis//模型封装//shiny_app", forceUpdate = TRUE)
# 在 R 中查看日志
rsconnect::showLogs(appName = "shiny_app", entries = 100)
# 确认依赖包是否正确安装
required_packages <- c("shiny", "e1071","caret","kernlab")
installed_packages <- installed.packages()
for (pkg in required_packages) {
if (!pkg %in% installed_packages) {
install.packages(pkg)
}
}
# 确认上述步骤都没有问题后，重新部署应用程序
rsconnect::deployApp(appDir = "//Users//huaiwenchang//Desktop//FDU D.Sc.//Aging/2023.5.18 Incremental Dialysis//Analysis//模型封装//shiny_app", forceUpdate = TRUE)
runApp()
# 确认上述步骤都没有问题后，重新部署应用程序
rsconnect::deployApp(appDir = "//Users//huaiwenchang//Desktop//FDU D.Sc.//Aging/2023.5.18 Incremental Dialysis//Analysis//模型封装//shiny_app", forceUpdate = TRUE)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
# 确认上述步骤都没有问题后，重新部署应用程序
rsconnect::deployApp(appDir = "//Users//huaiwenchang//Desktop//FDU D.Sc.//Aging/2023.5.18 Incremental Dialysis//Analysis//模型封装//shiny_app", forceUpdate = TRUE)
dta_scaled
